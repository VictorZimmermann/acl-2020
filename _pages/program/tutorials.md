---
title: Tutorials 
layout: single
excerpt: "ACL 2020 Tutorials."
permalink: /program/tutorials/
toc: true
toc_sticky: true
toc_icon: "cog"
sidebar: 
    nav: program

timezones:
  - url: "/assets/images/tutorial/timezones.png"
    image_path: "/assets/images/tutorial/timezones.png"
    alt: ""
    title: ""
timeslots:
  - url: "/assets/images/tutorial/timeslots.PNG"
    image_path: "/assets/images/tutorial/timeslots.PNG"
    alt: ""
    title: ""
t1:
  - url: "/assets/images/tutorial/1/belinkov_photo.jpg"
    image_path: "/assets/images/tutorial/1/belinkov_photo.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/1/gehrmann_photo.jpg"
    image_path: "/assets/images/tutorial/1/gehrmann_photo.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/1/Pavlick_09.jpg"
    image_path: "/assets/images/tutorial/1/Pavlick_09.jpg"
    alt: ""
    title: ""    
t2:
  - url: "/assets/images/tutorial/2/luna.jpeg"
    image_path: "/assets/images/tutorial/2/luna.jpeg"
    alt: ""
    title: "" 
  - url: "/assets/images/tutorial/2/hannaneh.jpg"
    image_path: "/assets/images/tutorial/2/hannaneh.jpg"
    alt: ""
    title: "" 
  - url: "/assets/images/tutorial/2/colin.jpeg"
    image_path: "/assets/images/tutorial/2/colin.jpeg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/2/prashant.jpeg"
    image_path: "/assets/images/tutorial/2/prashant.jpeg"
    alt: ""
    title: "" 
t3:
  - url: "/assets/images/tutorial/3/kevin.JPG"
    image_path: "/assets/images/tutorial/3/kevin.JPG"
    alt: ""
    title: ""  
  - url: "/assets/images/tutorial/3/karen.jpg"
    image_path: "/assets/images/tutorial/3/karen.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/3/Margot.png"
    image_path: "/assets/images/tutorial/3/Margot.png"
    alt: ""
    title: "" 
  - url: "/assets/images/tutorial/3/aurelie.jpg"
    image_path: "/assets/images/tutorial/3/aurelie.jpg"
    alt: ""
    title: "" 
t4:
  - url: "/assets/images/tutorial/4/Lili.png"
    image_path: "/assets/images/tutorial/4/Lili.png"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/4/Olga.png"
    image_path: "/assets/images/tutorial/4/Olga.png"
    alt: ""
    title: ""
t5:
  - url: "/assets/images/tutorial/5/OnMaHhGa_400x400.jpg"
    image_path: "/assets/images/tutorial/5/OnMaHhGa_400x400.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/5/P7220378.jpeg"
    image_path: "/assets/images/tutorial/5/P7220378.jpeg"
    alt: ""
    title: ""  
t6:
  - url: "/assets/images/tutorial/6/Maarten.jpg"
    image_path: "/assets/images/tutorial/6/Maarten.jpg"
    alt: ""
    title: "" 
  - url: "/assets/images/tutorial/6/Vered.jpg"
    image_path: "/assets/images/tutorial/6/Vered.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/6/Antoine.jpeg"
    image_path: "/assets/images/tutorial/6/Antoine.jpeg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/6/Yejin.jpg"
    image_path: "/assets/images/tutorial/6/Yejin.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/6/Dan.jpg"
    image_path: "/assets/images/tutorial/6/Dan.jpg"
    alt: ""
    title: ""
t7:
  - url: "/assets/images/tutorial/7/EmilyMBender2.jpg"
    image_path: "/assets/images/tutorial/7/EmilyMBender2.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/7/dirk-hovy.jpg"
    image_path: "/assets/images/tutorial/7/dirk-hovy.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/7/xanda.jpg"
    image_path: "/assets/images/tutorial/7/xanda.jpg"
    alt: ""
    title: ""  
t8:
  - url: "/assets/images/tutorial/8/danqi-photo.jpg"
    image_path: "/assets/images/tutorial/8/danqi-photo.jpg"
    alt: ""
    title: ""
  - url: "/assets/images/tutorial/8/scott-photo.jpg"
    image_path: "/assets/images/tutorial/8/scott-photo.jpg"
    alt: ""
    title: ""
---

## Tutorial timeslots

{% include gallery id="timezones" %}

{% include gallery id="timeslots" %}

- The table above shows 5 time slots defined for the ACL 2020 tutorials on <b>Sunday, July 5</b>. -1 means the day before (July 4), +1 means the day after (July 6).
- Sample zones and cities were chosen for reference, for other places, please, refer to the map above.
- Colors indicate slots judged as: <span style="background-color:#33cc33">convenient</span>, <span style="background-color:#ff9900">not very convenient</span>, <span style="background-color:#ff5050">inconvenient.
- If a tutorial can only be given <b>once</b> , slot 4 or 5 (optimal for Seattle) will be chosen.
- If a tutorial can be given <b>twice</b>, the teachers should propose <b>three slots</b> when they can make themselves available. Two out of these three slots will be chosen, for the best benefit of the teachers and the trainees.

## T1: Interpretability and Analysis in Neural NLP (cutting-edge) <br/>
*Organizers: Yonatan Belinkov, Sebastian Gehrmann and Ellie Pavlick* 
{% include gallery id="t1" %}

While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network models in NLP. This body of work is so far lacking a common framework and methodology. Moreover, approaching the analysis of modern neural networks can be difficult for newcomers to the field. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, such as structural analyses using probing classifiers, behavioral studies and test suites, and interactive visualizations. We will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches, in order to inform participants where to focus future efforts. 

## T2: Multi-modal Information Extraction from Text, Semi-structured, and Tabular Data on the Web (Cutting-edge) <br/>
*Organizers: Xin Luna Dong, Hannaneh Hajishirzi, Colin Lockard and Prashant Shiralkar* 
{% include gallery id="t2" %}

The World Wide Web contains vast quantities of textual information in several forms: unstructured text, template-based semi-structured webpages (which present data in key-value pairs and lists), and tables. Methods for extracting information from these sources and converting it to a structured form have been a target of research from the natural language processing (NLP), data mining, and database communities. While these researchers have largely separated extraction from web data into different problems based on the modality of the data, they have faced similar problems such as learning with limited labeled data, defining (or avoiding defining) ontologies, making use of prior knowledge, and scaling solutions to deal with the size of the Web. In this tutorial we take a holistic view toward information extraction, exploring the commonalities in the challenges and solutions developed to address these different forms of text. We will explore the approaches targeted at unstructured text that largely rely on learning syntactic or semantic textual patterns, approaches targeted at semi-structured documents that learn to identify structural patterns in the template, and approaches targeting web tables which rely heavily on entity linking and type information. While these different data modalities have largely been considered separately in the past, recent research has started taking a more inclusive approach toward textual extraction, in which the multiple signals offered by textual, layout, and visual clues are combined into a single extraction model made possible by new deep learning approaches. At the same time, trends within purely textual extraction have shifted toward full-document understanding rather than considering sentences as independent units. With this in mind, it is worth considering the information extraction problem as a whole to motivate solutions that harness textual semantics along with visual and semi-structured layout information. We will discuss these approaches and suggest avenues for future work. 

See <a href="https://sites.google.com/view/acl-2020-multi-modal-ie">https://sites.google.com/view/acl-2020-multi-modal-ie</a> for the tutorial material.

## T3: Reviewing Natural Language Processing Research (Introductory) <br/>
*Organizers: Kevin Cohen, Karën Fort, Margot Mieskes and Aurélie Névéol* 
{% include gallery id="t3" %}

This tutorial will cover the theory and practice of reviewing research in natural language processing. Heavy reviewing burdens on natural language processing researchers have made it clear that our community needs to increase the size of our pool of potential reviewers. Simultaneously, notable false negatives---rejection by our conferences of work that was later shown to be tremendously important after acceptance by other conferences---have raised awareness of the fact that our reviewing practices leave something to be desired. We do not often talk about false positives with respect to conference papers, but leaders in the field have noted that we seem to have a publication bias towards papers that report high performance, with perhaps not much else of interest in them. It need not be this way. Reviewing is a learnable skill, and you will learn it here via lectures and a considerable amount of hands-on practice. 

## T4: Stylized Text Generation: Approaches and Applications (Cutting-edge) <br/>
*Organizers: Lili Mou and Olga Vechtomova* 
{% include gallery id="t4" %}

Text generation has played an important role in various applications of natural language processing (NLP), and recent studies, researchers are paying increasing attention to modeling and manipulating the style of the generation text, which we call stylized text generation. In this tutorial, we will provide a comprehensive literature review in this direction. We start from the definition of style and different settings of stylized text generation, illustrated with various applications. Then, we present different settings of stylized generation, such as style-conditioned generation, style-transfer generation, and style-adversarial generation. In each setting, we delve deep into machine learning methods, including embedding learning techniques to represent style, adversarial learning, and reinforcement learning with cycle consistency to match content but to distinguish different styles. We also introduce current approaches to evaluating stylized text generation systems. We conclude our tutorial by presenting the challenges of stylized text generation and discussing future directions, such as small-data training, non-categorical style modeling, and a generalized scope of style transfer (e.g., controlling the syntax as a style).  

See <a href="https://lili-mou.github.io/">https://lili-mou.github.io/</a> for the tutorial material.

			
## T5: Achieving Common Ground in Multi-modal Dialogue (Cutting-edge) <br/>
*Organizers: Malihe Alikhani and Matthew Stone* 
{% include gallery id="t5" %}

All communication aims at achieving common ground (grounding): interlocutors can work together effectively only with mutual beliefs about what the state of the world is, about what their goals are, and about how they plan to make their goals a reality. Computational dialogue research offers some classic results on grouding, which unfortunately offer scant guidance to the design of grounding modules and behaviors in cutting-edge systems. In this tutorial, we focus on three main topic areas: 1) grounding in human-human communication; 2) grounding in dialogue systems; and 3) grounding in multi-modal interactive systems, including image-oriented conversations and human-robot interactions. We highlight a number of achievements of recent computational research in coordinating complex content, show how these results lead to rich and challenging opportunities for doing grounding in more flexible and powerful ways, and canvass relevant insights from the literature on human--human conversation. We expect that the tutorial will be of interest to researchers in dialogue systems, computational semantics and cognitive modeling, and hope that it will catalyze research and system building that more directly explores the creative, strategic ways conversational agents might be able to seek and offer evidence about their understanding of their interlocutors.

See <a href="https://github.com/malihealikhani/Grounding_in_Dialogue">https://github.com/malihealikhani/Grounding_in_Dialogue</a> for the tutorial material.

## T6: Commonsense Reasoning for Natural Language Processing (Introductory) <br/>
*Organizers: Maarten Sap, Vered Shwartz, Antoine Bosselut, Yejin Choi, Dan Roth* 
{% include gallery id="t6" %}

Commonsense knowledge, such as knowing that "bumping into people annoys them" or "rain makes the road slippery", helps humans navigate everyday situations seamlessly. Yet, endowing machines with such human-like commonsense reasoning capabilities has remained an elusive goal of artificial intelligence research for decades. In recent years, commonsense knowledge and reasoning have received renewed attention from the natural language processing (NLP) community, yielding exploratory studies in automated commonsense understanding. We organize this tutorial to provide researchers with the critical foundations and recent advances in commonsense representation and reasoning, in the hopes of casting a brighter light on this promising area of future research. In our tutorial, we will (1) outline the various types of commonsense (e.g., physical, social), and (2) discuss techniques to gather and represent commonsense knowledge, while highlighting the challenges specific to this type of knowledge (e.g., reporting bias). We will then (3) discuss the types of commonsense knowledge captured by modern NLP systems (e.g., large pretrained language models), and (4) present ways to measure systems' commonsense reasoning abilities. We will finish with (5) a discussion of various ways in which commonsense reasoning can be used to improve performance on NLP tasks, exemplified by an (6) interactive session on integrating commonsense into a downstream task. 

See <a href="https://tinyurl.com/acl2020-commonsense">https://tinyurl.com/acl2020-commonsense</a> for the tutorial material.

## T7: Integrating Ethics into the NLP Curriculum (Introductory) <br/>
*Organizers: Emily M. Bender, Dirk Hovy and Alexandra Schofield* 
{% include gallery id="t7" %}

To raise awareness among future NLP practitioners and prevent inertia in the field, we need to place ethics in the curriculum for all NLP students---not as an elective, but as a core part of their education. Our goal in this tutorial is to empower NLP researchers and practitioners with tools and resources to teach others about how to ethically apply NLP techniques. We will present both high-level strategies for developing an ethics-oriented curriculum, based on experience and best practices, as well as specific sample exercises that can be brought to a classroom. This highly interactive work session will culminate in a shared online resource page that pools lesson plans, assignments, exercise ideas, reading suggestions, and ideas from the attendees. Though the tutorial will focus particularly on examples for university classrooms, we believe these ideas can extend to company-internal workshops or tutorials in a variety of organizations. In this setting, a key lesson is that there is no single approach to ethical NLP: each project requires thoughtful consideration about what steps can be taken to best support people affected by that project. However, we can learn (and teach) what issues to be aware of, what questions to ask, and what strategies are available to mitigate harm. 

### T8: Open-Domain Question Answering (Cutting-edge) <br/>
*Organizers: Danqi Chen and Scott Wen-tau Yih* 
{% include gallery id="t8" %}

This tutorial provides a comprehensive and coherent overview of cutting-edge research in open-domain question answering (QA), the task of answering questions using a large collection of documents of diversified topics. We will start by first giving a brief historical background, discussing the basic setup and core technical challenges of the research problem, and then describe modern datasets with the common evaluation metrics and benchmarks. The focus will then shift to cutting-edge models proposed for open-domain QA, including two-stage retriever-reader approaches, dense retriever and end-to-end training, and retriever-free methods. Finally, we will cover some hybrid approaches using both text and large knowledge bases and conclude the tutorial with important open questions. We hope that the tutorial will not only help the audience to acquire up-to-date knowledge but also provide new perspectives to stimulate the advances of open-domain QA research in the next phase. 

See <a href="https://github.com/danqi/acl2020-openqa-tutorial">https://github.com/danqi/acl2020-openqa-tutorial</a> for the tutorial material.


